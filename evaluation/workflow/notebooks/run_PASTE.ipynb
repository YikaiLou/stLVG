{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import style\n",
    "import paste as pst\n",
    "import ot\n",
    "import seaborn\n",
    "from anndata import AnnData\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from typing import List, Mapping, Optional, Union\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi_save=200,dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter cells\n",
    "adata1_file = ''\n",
    "adata2_file = ''\n",
    "metrics_file = ''\n",
    "matching_file = ''\n",
    "\n",
    "# hyperparameters\n",
    "alpha = 0.0\n",
    "\n",
    "# emb0_file = '' # PASTE do not have emb \n",
    "# emb1_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_seed(seed: int):\n",
    "    r\"\"\"\n",
    "    Set seed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seed \n",
    "        int\n",
    "    \"\"\"\n",
    "    seed = seed if seed != -1 else torch.seed()\n",
    "    if seed > 2**32 - 1:\n",
    "        seed = seed >> 32\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"Global seed set to {seed}.\")\n",
    "\n",
    "def get_metric(adatas:List[AnnData],\n",
    "                matching:np.ndarray,\n",
    "                biology_meta:Optional[str]='',\n",
    "                topology_meta:Optional[str]=''\n",
    "    ) -> float:\n",
    "    for adata in adatas:\n",
    "        assert biology_meta in adata.obs.columns or topology_meta in adata.obs.columns\n",
    "        if biology_meta not in adata.obs:\n",
    "            adata.obs[biology_meta] = 'Unknown'\n",
    "            print(f\"Warning!,biology_meta not in adata.obs \")\n",
    "        elif topology_meta not in adata.obs:\n",
    "            adata.obs[topology_meta] = 'Unknown'\n",
    "            print(f\"Warning!,topology_meta not in adata.obs \")\n",
    "        adata.obs['global_meta'] = adata.obs[biology_meta].astype(str) + '-' + adata.obs[topology_meta].astype(str)\n",
    "    count = 0\n",
    "    for i in range(matching.shape[0]): # query dataset\n",
    "        query_meta = adatas[1].obs.iloc[i].loc['global_meta']\n",
    "        ref_meta = adatas[0].obs.iloc[matching[i,1]].loc['global_meta']\n",
    "        count = count + 1 if query_meta == ref_meta else count\n",
    "    score = count/adatas[1].shape[0]\n",
    "    \n",
    "    return score\n",
    "\n",
    "def scanpy_workflow(adata:AnnData,\n",
    "                    n_top_genes:Optional[int]=2500,\n",
    "                    n_comps:Optional[int]=50\n",
    "    ) -> AnnData:\n",
    "    r\"\"\"\n",
    "    Scanpy workflow using Seurat HVG\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        adata\n",
    "    n_top_genes\n",
    "        n top genes\n",
    "    n_comps\n",
    "        n PCA components\n",
    "    \"\"\"\n",
    "    if 'counts' not in adata.layers.keys():\n",
    "        adata.layers[\"counts\"] = adata.X.copy()\n",
    "    if \"highly_variable\" not in adata.var_keys():\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor=\"seurat_v3\")\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.scale(adata)\n",
    "    sc.tl.pca(adata, n_comps=n_comps, svd_solver=\"auto\")\n",
    "    return adata.copy()\n",
    "\n",
    "\n",
    "class match_3D_multi():\n",
    "    r\"\"\"\n",
    "    Plot the mapping result between 2 datasets\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    dataset_A\n",
    "        pandas dataframe which contain ['index','x','y'], reference dataset\n",
    "    dataset_B\n",
    "        pandas dataframe which contain ['index','x','y'], target dataset\n",
    "    matching\n",
    "        matching results\n",
    "    meta\n",
    "        dataframe colname of meta, such as celltype\n",
    "    expr\n",
    "        dataframe colname of gene expr\n",
    "    subsample_size\n",
    "        subsample size of matches\n",
    "    reliability\n",
    "        match score (cosine similarity score)\n",
    "    scale_coordinate\n",
    "        if scale coordinate via (:math:`data - np.min(data)) / (np.max(data) - np.min(data))`)\n",
    "    rotate\n",
    "        how to rotate the slides (force scale_coordinate), such as ['x','y'], means dataset0 rotate on x axes\n",
    "        and dataset1 rotate on y axes\n",
    "    change_xy\n",
    "        exchange x and y on dataset_B\n",
    "\n",
    "    Note\n",
    "    ----------\n",
    "    dataset_A and dataset_B can in different length\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self,dataset_A:pd.DataFrame,\n",
    "                 dataset_B: pd.DataFrame,\n",
    "                 matching: np.ndarray,\n",
    "                 meta: Optional[str] = None,\n",
    "                 expr: Optional[str] = None,\n",
    "                 subsample_size: Optional[int]=300,\n",
    "                 reliability: Optional[np.ndarray]=None,\n",
    "                 scale_coordinate: Optional[bool]=True,\n",
    "                 rotate: Optional[List[str]]=None,\n",
    "                 exchange_xy: Optional[bool]=False\n",
    "        ) -> None:\n",
    "        self.dataset_A = dataset_A.copy()\n",
    "        self.dataset_B = dataset_B.copy()\n",
    "        self.meta = meta\n",
    "        self.matching= matching\n",
    "        self.conf = reliability\n",
    "        scale_coordinate = True if rotate != None else scale_coordinate\n",
    "        \n",
    "        assert all(item in dataset_A.columns.values for item in ['index','x','y'])\n",
    "        assert all(item in dataset_B.columns.values for item in ['index','x','y'])\n",
    "        \n",
    "        if meta:\n",
    "            self.celltypes = set(self.dataset_A[meta].append(self.dataset_B[meta]))\n",
    "            set1 = list(set(self.dataset_A[meta]))\n",
    "            set2 = list(set(self.dataset_B[meta]))\n",
    "            overlap = [x for x in set2 if x in set1]\n",
    "            print(f\"dataset1: {len(set1)} cell types; dataset2: {len(set2)} cell types; \\n\\\n",
    "                    All :{len(self.celltypes)} celltypes; Overlap: {len(overlap)} cell types \\n\\\n",
    "                    Not overlap :[{[y for y in (set1+set2) if y not in overlap]}]\"\n",
    "                    )\n",
    "        self.expr = expr if expr else False\n",
    "            \n",
    "        if scale_coordinate:\n",
    "            for i, dataset in enumerate([self.dataset_A, self.dataset_B]):\n",
    "                for axis in ['x','y']:\n",
    "                    dataset[axis] = (dataset[axis] - np.min(dataset[axis])) / (np.max(dataset[axis])- np.min(dataset[axis]))\n",
    "                    if rotate == None:\n",
    "                        pass\n",
    "                    elif axis in rotate[i]:\n",
    "                        dataset[axis] = 1 - dataset[axis]\n",
    "        if exchange_xy:\n",
    "            self.dataset_B[['x','y']] = self.dataset_B[['y','x']]\n",
    "\n",
    "        subsample_size = subsample_size if matching.shape[1] > subsample_size else matching.shape[1]\n",
    "        print(f'Subsample {subsample_size} cell pairs from {matching.shape[1]}')\n",
    "        self.matching = matching[:,np.random.choice(matching.shape[1],subsample_size, replace=False)]\n",
    "            \n",
    "        self.datasets = [self.dataset_A, self.dataset_B]\n",
    "    \n",
    "    def draw_3D(self,\n",
    "                size: Optional[List[int]]=[10,10],\n",
    "                point_size: Optional[List[int]]=[0.1,0.1],\n",
    "                line_width: Optional[float]=0.3,\n",
    "                line_color:Optional[str]='grey',\n",
    "                line_alpha: Optional[float]=0.7,\n",
    "                hide_axis: Optional[bool]=False,\n",
    "                show_error: Optional[bool]=True,\n",
    "                cmap: Optional[bool]='Reds',\n",
    "                save:Optional[str]=None\n",
    "        ) -> None:\n",
    "        r\"\"\"\n",
    "        Draw 3D picture of two datasets\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        size\n",
    "            plt figure size\n",
    "        point_size\n",
    "            point size of every dataset\n",
    "        line_width\n",
    "            pair line width\n",
    "        line_color\n",
    "            pair line color\n",
    "        line_alpha\n",
    "            pair line alpha\n",
    "        hide_axis\n",
    "            if hide axis\n",
    "        show_error\n",
    "            if show error celltype mapping with different color\n",
    "        cmap\n",
    "            color map when vis expr\n",
    "        save\n",
    "            save file path\n",
    "        \"\"\"\n",
    "        show_error = show_error if self.meta else False\n",
    "        fig = plt.figure(figsize=(size[0],size[1]))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        # color by different cell types\n",
    "        if self.meta:\n",
    "            color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(self.celltypes))]\n",
    "            c_map = {}\n",
    "            for i, celltype in enumerate(self.celltypes):\n",
    "                c_map[celltype] = color[i]\n",
    "            if self.expr:\n",
    "                c_map = cmap\n",
    "                # expr_concat = pd.concat(self.datasets)[self.expr].to_numpy()\n",
    "                # norm = plt.Normalize(expr_concat.min(), expr_concat.max())\n",
    "            for i, dataset in enumerate(self.datasets):\n",
    "                if self.expr:\n",
    "                    norm = plt.Normalize(dataset[self.expr].to_numpy().min(), dataset[self.expr].to_numpy().max())\n",
    "                for cell_type in self.celltypes:\n",
    "                    slice = dataset[dataset[self.meta] == cell_type]\n",
    "                    xs = slice['x']\n",
    "                    ys = slice['y']\n",
    "                    zs = i\n",
    "                    if self.expr:\n",
    "                        ax.scatter(xs,ys,zs,s=point_size[i],c=slice[self.expr],cmap=c_map,norm=norm)\n",
    "                    else:\n",
    "                        ax.scatter(xs,ys,zs,s=point_size[i],c=c_map[cell_type])\n",
    "                    \n",
    "        # plot different point layers\n",
    "        else:\n",
    "            for i, dataset in enumerate(self.datasets):\n",
    "                xs = dataset['x']\n",
    "                ys = dataset['y']\n",
    "                zs = i\n",
    "                ax.scatter(xs,ys,zs,s=point_size[i])\n",
    "        \n",
    "        # plot line\n",
    "        self.draw_lines(ax,show_error,line_color,line_width,line_alpha)\n",
    "        if hide_axis:\n",
    "            plt.axis('off')\n",
    "        if save != None:\n",
    "            plt.savefig(save)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def draw_lines(self,ax,show_error,default_color,line_width=0.3,line_alpha=0.7) -> None:\n",
    "        r\"\"\"\n",
    "        Draw lines between paired cells in two datasets\n",
    "        \"\"\"\n",
    "        for i in range(self.matching.shape[1]):\n",
    "            pair = self.matching[:,i]\n",
    "            default_color = default_color\n",
    "            if self.meta != None:\n",
    "                if self.dataset_B.loc[self.dataset_B['index']==pair[0], self.meta].astype(str).values ==\\\n",
    "                    self.dataset_A.loc[self.dataset_A['index']==pair[1], self.meta].astype(str).values:\n",
    "                    color = '#ade8f4' # blue\n",
    "                else:\n",
    "                    color = '#ffafcc'  # red\n",
    "                if self.conf:\n",
    "                    if color == '#ade8f4' and not self.conf[i]: # low reliability but right\n",
    "                        color = '#588157' # green\n",
    "                    elif color == '#ffafcc' and self.conf[i]: # high reliability but error\n",
    "                        color = '#ffb703' # yellow\n",
    "                \n",
    "            point0 = np.append(self.dataset_A[self.dataset_A['index']==pair[1]][['x','y']], 0)\n",
    "            point1 = np.append(self.dataset_B[self.dataset_B['index']==pair[0]][['x','y']], 1)\n",
    "            coord = np.row_stack((point0,point1))\n",
    "            color = color if show_error else default_color\n",
    "            ax.plot(coord[:,0], coord[:,1], coord[:,2], color=color, linestyle=\"dashed\", linewidth=line_width, alpha=line_alpha)\n",
    "\n",
    "\n",
    "def euclidean_dis(adata1:AnnData,\n",
    "                  adata2:AnnData,\n",
    "                  matching:np.ndarray,\n",
    "                  spatial_key:Optional[str]='spatial'\n",
    "    ) -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    Calculate euclidean distance between two datasets with ground truth\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata1\n",
    "        adata1 with spatial\n",
    "    adata2\n",
    "        adata2 with spatial\n",
    "    matching\n",
    "        matching result\n",
    "    spatial_key\n",
    "        key of spatial data in adata.obsm\n",
    "    \"\"\"\n",
    "    # reindex adata1 and adata2 by matching then calculate the pairwise euclidean distance\n",
    "    if abs(adata1.obsm[spatial_key].max()) > 1 or abs(adata1.obsm[spatial_key].min()) > 1:\n",
    "        adata1.obsm['scale_spatial'] = adata1.obsm[spatial_key]/adata1.obsm[spatial_key].max()\n",
    "    if abs(adata2.obsm[spatial_key].max()) > 1 or abs(adata2.obsm[spatial_key].min()) > 1:\n",
    "        adata2.obsm['scale_spatial'] = adata2.obsm[spatial_key]/adata2.obsm[spatial_key].max()\n",
    "    spatial_key = 'scale_spatial'\n",
    "    coord1 = adata1.obsm[spatial_key][matching[1,:]]\n",
    "    coord2 = adata2.obsm[spatial_key]\n",
    "    distance = np.sqrt((coord1[:,0] - coord2[:,0])**2+(coord1[:,1] - coord2[:,1])**2)\n",
    "    return float(distance.sum()/distance.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1 = sc.read_h5ad(adata1_file)\n",
    "adata2 = sc.read_h5ad(adata2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pi0 = pst.match_spots_using_spatial_heuristic(adata1.obsm['spatial'], adata2.obsm['spatial'], use_ot=True)\n",
    "pi12 = pst.pairwise_align(adata1, adata2,\n",
    "                          use_gpu=torch.cuda.is_available(),\n",
    "                          backend=ot.backend.TorchBackend(), \n",
    "                          alpha=alpha, G_init=pi0, norm=True, verbose=True)\n",
    "print('Runtime: ' + str(time.time() - start))\n",
    "run_time = str(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(pi12)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_index = np.argmax(result.to_numpy(),axis=0)\n",
    "matching = np.array([np.arange(result.shape[1]),matching_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'visium' and 'DLPFC' in adata1_file:\n",
    "    biology_meta = 'cell_type'\n",
    "    topology_meta = 'layer_guess'\n",
    "elif 'merfish' and 'hypothalamic' in adata1_file:\n",
    "    biology_meta = 'Cell_class'\n",
    "    topology_meta = 'region'\n",
    "elif 'stereo' and 'embryo' in adata1_file:\n",
    "    biology_meta = 'annotation'\n",
    "    topology_meta = 'region'\n",
    "elif 'brain' in adata1_file:\n",
    "    biology_meta = 'layer_guess'\n",
    "    topology_meta = 'layer_guess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = get_metric([adata1,adata2], matching.T, biology_meta, topology_meta)\n",
    "celltype_score = get_metric([adata1,adata2], matching.T, biology_meta=biology_meta)\n",
    "region_score = get_metric([adata1,adata2], matching.T, topology_meta=topology_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eud = euclidean_dis(adata1, adata2, matching)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(os.path.dirname(metrics_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save\n",
    "metric_dic = {}\n",
    "metric_dic['global_score'] = metric\n",
    "metric_dic['celltype_score'] = celltype_score\n",
    "metric_dic['region_score'] = region_score\n",
    "metric_dic['euclidean_dis'] = eud\n",
    "metric_dic['run_time'] = run_time\n",
    "\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    yaml.dump(metric_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(matching_file, matching, fmt='%i')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pl.spatial(adata1, color = [biology_meta, topology_meta], spot_size=5)\n",
    "# sc.pl.spatial(adata2, color = [biology_meta, topology_meta], spot_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pis = [pi12]\n",
    "# slices = [adata1, adata2]\n",
    "\n",
    "# new_slices = pst.stack_slices_pairwise(slices, pis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice_colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3']\n",
    "\n",
    "# plt.figure(figsize=(7,7))\n",
    "# for i in range(len(new_slices)):\n",
    "#     pst.plot_slice(new_slices[i],slice_colors[i],s=50)\n",
    "# plt.legend(handles=[mpatches.Patch(color=slice_colors[0], label='1'),mpatches.Patch(color=slice_colors[1], label='2')])\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.axis('off')\n",
    "# plt.savefig(out_dir / 'PASTE.pdf', dpi=200, format ='pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata1_df = pd.DataFrame({'index':range(adata1.shape[0]),\n",
    "#                           'x': adata1.obsm['spatial'][:,0],\n",
    "#                           'y': adata1.obsm['spatial'][:,1],\n",
    "#                           'celltype':adata1.obs[biology_meta],\n",
    "#                           'region':adata1.obs[topology_meta]})\n",
    "# adata2_df = pd.DataFrame({'index':range(adata2.shape[0]),\n",
    "#                           'x': adata2.obsm['spatial'][:,0],\n",
    "#                           'y': adata2.obsm['spatial'][:,1],\n",
    "#                           'celltype':adata2.obs[biology_meta],\n",
    "#                           'region':adata2.obs[topology_meta]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_align = match_3D_multi(adata1_df, adata2_df,matching,meta='celltype',\n",
    "#                              scale_coordinate=True,subsample_size=300,exchange_xy=False)\n",
    "\n",
    "# multi_align.draw_3D(size=[7, 8], line_width =1, point_size=[0.8,0.8], hide_axis=True, show_error=True, save=out_dir / 'match_by_celltype.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_align = match_3D_multi(adata1_df, adata2_df,matching,meta='region',\n",
    "#                              scale_coordinate=True,subsample_size=300,exchange_xy=False)\n",
    "\n",
    "# multi_align.draw_3D(size=[7, 8],line_width=1, point_size=[0.8,0.8], hide_axis=True, show_error=True, save=out_dir / 'match_by_region.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:18) \n[GCC 10.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "88786030ea59a7c96004ff67a345d53abff4d58eacfbb401c324cb520462373b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
